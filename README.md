# Local Private AI within your machine 

## ‚ö†Ô∏è Make sure your device/machine have the enough captibilty for this project as the follow : 
1. 8GB minimum of RAM
2. latest OS - For example Windows 11
3. 10th intel i3 as minimum CPU
4. At least 8Gb GPU

# üìö You will need to install the following : 
1. WSL in windows opreating system OR linux VM or machine running linux
2. install ollama package into your linux system
3. install obsidian software
4. Your local port is not used by other software to make sure the AI can run locally!

# Step 1 
In Documentation #1, I focus on establishing a robust foundation by setting up Ollama for managing AI models locally, optimizing my WSL-based Ubuntu environment for advanced AI frameworks, and integrating cybersecurity practices to ensure a secure, isolated AI ecosystem. This project bridges technical and personal growth, applying concepts from my IBM AI Fundamentals course to hands-on experience at the intersection of machine learning and cybersecurity. I aim to share insights, engage with the community, and contribute to shaping the future of secure, open-source AI development. üåü
![documentation #1](https://github.com/user-attachments/assets/8a3c94b3-0d25-49ca-b5d9-9ccacd8fc417)

# Step 2
Today, Now installed the Ollama model package on my local machine and linked it to a web UI interface, tackling the challenge of using Docker for the first time. Key achievements included configuring the AI model for private use, setting up Docker to manage and connect the model with the interface, and resolving a linking issue through in-depth debugging and study of Docker‚Äôs networking configurations. This 1.5-hour effort culminated in launching a private ChatGPT web interface locally, enriching my understanding of containerization, network ports, and their practical applications. This journey into AI, open-source tools, and cybersecurity remains both challenging and rewarding. üåü
![image](https://github.com/user-attachments/assets/bb6cb6cb-86f7-4752-b954-f092ce6a1c0e)


# Step 3
Today, Now implemented Identity and Access Management (IAM) principles and networking configurations to enable secure access to my AI assistant from another user account. By configuring user permissions with Linux terminal commands, I ensured role-specific access while safeguarding sensitive data. Identifying my machine‚Äôs local IP address using OSI model concepts allowed me to establish secure communication between accounts, culminating in linking another user to the assistant with controlled interaction. This milestone deepened my understanding of balancing functionality with privacy and highlighted the importance of securing AI systems. üåü
![image](https://github.com/user-attachments/assets/b832ffa3-cba2-4a6d-a547-9daae63a36af)

# Step 4 
Now, integrated my local AI assistant with Obsidian, my second favorite note-taking software, creating a private, productivity-enhancing tool. Leveraging an API endpoint from the Ollama WebUI, I enabled secure communication between the AI and Obsidian, ensuring all interactions remain local. I customized workflows within Obsidian using plugins and scripts, enabling my AI to summarize complex notes, generate insights, and assist with task planning. After extensive testing and refinement, this integration proved transformative, showcasing the power of locally hosted AI to boost productivity without compromising privacy. üåü
![image](https://github.com/user-attachments/assets/e669b4f2-5795-4cab-b80c-106c97e2c4ae)



